{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b6be1-7b91-489e-9c4c-1badfc7d8ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3.10.15/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:59: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.\n",
      "  warnings.warn(f\"Warning: The {path} owner does not match the current owner.\")\n",
      "/usr/local/python3.10.15/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:59: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.0.0/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.\n",
      "  warnings.warn(f\"Warning: The {path} owner does not match the current owner.\")\n",
      "/usr/local/python3.10.15/lib/python3.10/site-packages/torch_npu/__init__.py:248: UserWarning: On the interactive interface, the value of TASK_QUEUE_ENABLE is set to 0 by default.                      Do not set it to 1 to prevent some unknown errors\n",
      "  warnings.warn(\"On the interactive interface, the value of TASK_QUEUE_ENABLE is set to 0 by default. \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_npu\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device=torch.device('npu')\n",
    "train_data = pd.read_csv('/aistor/aispeech/hpc_stor01/home/xuruoxi00sx/ttt/daily_train.csv')\n",
    "test_data = pd.read_csv('/aistor/aispeech/hpc_stor01/home/xuruoxi00sx/ttt/daily_test.csv')\n",
    "\n",
    "# 选择特征和目标列\n",
    "# features = ['season', 'holiday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "features = [\n",
    "    \"Global_reactive_power\", \"Sub_metering_1\", \"Sub_metering_2\", \"Sub_metering_3\",\n",
    "    \"sub_metering_remainder\", \"Voltage\", \"Global_intensity\", \"RR\",\n",
    "    \"NBJRR1\", \"NBJRR5\", \"NBJRR10\", \"NBJBROU\"\n",
    "]\n",
    "target = \"Global_active_power\"\n",
    "\n",
    "# 参数定义\n",
    "look_back = 90\n",
    "T = 365  # 预测未来90步\n",
    "batch_size = 256\n",
    "epochs = 500\n",
    "learn_rate = 0.0002\n",
    "input_dim = len(features)\n",
    "hidden_dim = 32\n",
    "num_layers = 8\n",
    "dropout = 0.2\n",
    "device=torch.device('npu')\n",
    "# 数据预处理：归一化\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "train_data[features] = scaler_features.fit_transform(train_data[features])\n",
    "train_data[target] = scaler_target.fit_transform(train_data[[target]])\n",
    "test_data[features] = scaler_features.transform(test_data[features])\n",
    "test_data[target] = scaler_target.transform(test_data[[target]])\n",
    "\n",
    "train_data[features] = train_data[features].fillna(train_data[features].mean())\n",
    "test_data[features] = test_data[features].fillna(test_data[features].mean())\n",
    "\n",
    "# 构建时间序列数据（包含前90步和后90步特征）\n",
    "def create_sequences_with_future_features(data, features, target, look_back, pred_len):\n",
    "    X, y = [], []\n",
    "    for i in range(0, len(data) - look_back - pred_len, look_back):\n",
    "        # 前90步特征\n",
    "        X_past = data[features].iloc[i:i + look_back].values\n",
    "        # 后90步特征\n",
    "        X_future = data[features].iloc[i + look_back:i + look_back + pred_len].values\n",
    "        # 拼接前后特征：形状 [180, feature_dim]\n",
    "        X_combined = np.concatenate([X_past, X_future], axis=0)\n",
    "        y_seq = data[target].iloc[i + look_back:i + look_back + pred_len].values\n",
    "        X.append(X_combined)\n",
    "        y.append(y_seq)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 构造数据\n",
    "X_train, y_train = create_sequences_with_future_features(train_data, features, target, look_back, T)\n",
    "X_test, y_test = create_sequences_with_future_features(test_data, features, target, look_back, T)\n",
    "\n",
    "# 转换为 PyTorch Tensor \n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 构建数据加载器\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class DLinearLSTM(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, feature_dim, hidden_dim=12, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        # 为每个特征单独建立LSTM + Linear\n",
    "        self.lstms = nn.ModuleList([\n",
    "            nn.LSTM(\n",
    "                input_size=1, hidden_size=hidden_dim, num_layers=num_layers,\n",
    "                batch_first=True, dropout=dropout if num_layers > 1 else 0\n",
    "            )\n",
    "            for _ in range(feature_dim)\n",
    "        ])\n",
    "        self.linears = nn.ModuleList([\n",
    "            nn.Linear(seq_len, pred_len)\n",
    "            for _ in range(feature_dim)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, seq_len, feature_dim]\n",
    "        outs = []\n",
    "        for i in range(self.feature_dim):\n",
    "            xi = x[:, :, i].unsqueeze(-1)  # [B, seq_len, 1]\n",
    "            lstm_out, _ = self.lstms[i](xi)  # [B, seq_len, hidden_dim]\n",
    "            # 仅用最后一层的最后一维，或全局平均池化\n",
    "            pooled = lstm_out.mean(-1)  # [B, seq_len] (对hidden_dim做均值)\n",
    "            outi = self.linears[i](pooled)  # [B, pred_len]\n",
    "            outs.append(outi.unsqueeze(-1))\n",
    "        out = torch.cat(outs, dim=-1)  # [B, pred_len, feature_dim]\n",
    "        out = out.mean(dim=-1)         # [B, pred_len]\n",
    "        return out\n",
    "\n",
    "model = DLinearLSTM(\n",
    "    seq_len=look_back+T,   # 180\n",
    "    pred_len=T,            # 90\n",
    "    feature_dim=input_dim, # 12\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# 损失函数与优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=learn_rate)\n",
    "\n",
    "# 梯度裁剪函数\n",
    "def clip_gradients(model, max_norm=1.0):\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "\n",
    "# 训练模型\n",
    "train_losses = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        if torch.isnan(loss):\n",
    "            raise ValueError(\"Loss became NaN during training.\")\n",
    "\n",
    "        loss.backward()\n",
    "        clip_gradients(model)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d9c28-07e4-465e-87c9-248021cab8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        actuals.extend(y_batch.cpu().numpy())\n",
    "\n",
    "\n",
    "predictions = (np.array(predictions).reshape(-1, 1))\n",
    "actuals = (np.array(actuals).reshape(-1, 1))\n",
    "\n",
    "# 反归一化\n",
    "predictions = scaler_target.inverse_transform(predictions)\n",
    "actuals = scaler_target.inverse_transform(actuals)\n",
    "\n",
    "best_i = -1\n",
    "mse = float('inf')\n",
    "mse_list = []\n",
    "mae_list = []\n",
    "for i in range(90,len(actuals)-T):\n",
    "    tmp = mean_absolute_error(actuals[i:i+T], predictions[i:i+T])\n",
    "    # print(actuals[i][:1],predictions[i][:1])\n",
    "    mae_list.append(tmp)\n",
    "    mse_list.append(mean_squared_error(actuals[i:i+T], predictions[i:i+T]))\n",
    "    if tmp < mse:\n",
    "        mse = tmp\n",
    "        best_i = i\n",
    "# print(len(mse_list))\n",
    "# print(len(mae_list))\n",
    "print('mse:', sum(mse_list)/len(mse_list))\n",
    "print('mae:', sum(mae_list)/len(mae_list))\n",
    "\n",
    "i = best_i\n",
    "# i=107\n",
    "y1 = np.concatenate((actuals[i-90:i], actuals[i:i+T]))\n",
    "y2 = predictions[i:i+T]\n",
    "# print(len(actuals[i-90:i]),len(y1),len(y2))\n",
    "# 计算两条曲线的 x 轴范围\n",
    "x1 = np.arange(len(y1))  # x1: [0, 1, 2, 3]\n",
    "x2 = np.arange(len(y1) - len(y2), len(y1))  # x2: [2, 3]\n",
    "plt.figure(figsize=(8, 8))\n",
    "# 绘制曲线\n",
    "plt.plot(x1, y1, label=\"True\")  # 第一条曲线\n",
    "plt.plot(x2, y2, label=\"Prediction\")  # 第二条曲线\n",
    "\n",
    "# 添加图例和标题\n",
    "plt.legend()\n",
    "\n",
    "# plt.xlabel(\"X\")\n",
    "# plt.ylabel(\"Y\")\n",
    "# plt.savefig(\"img/output_lstm_short_%d.png\"%i)\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22eb7c6-e8b4-4db5-9216-d47af15d2a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c343933d-3732-4a3c-bcab-379a96cb3a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (xrx)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
